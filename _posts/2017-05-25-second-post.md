---
title: Saliency Detection based on Fusion and Segmentation
author: Chris
layout: post
---

An unsupervised saliency detection model based on Fusion and Segmentation. The paper is submitted to ICME2018.


<span class="image left"><img src="{{ 'assets/myimg/pic1.jpg' | relative_url }}" alt="" /></span>

<p style="text-align:justify">
We proposed an unsupervised saliency objects extraction method for 3D video. The proposed framework consists of three main stages: (i) The input video frame is segmented into non-overlapping superpixels by combining both appearance and depth information at the input. Depth information can be used to improve the accuracy of segmentation in complex regions, i.e., foreground object with similar appearance as background. A multi-scale segmentation scheme is also deployed by using different segmentation parameters to extract varying shapes of the foregrounds in each frame. (ii) The initial saliency score of each segmented superpixel in each scale is calculated via global contrast which is defined by appearance, depth, and motion cues from two consecutive frames. (iii) The initial saliency scores in each scale are refined by smoothing over a graph built by the spatial neighboring of all the superpixels in the frame. The final result is generated by fusing the saliency maps in all scales. This model also achieved unsupervised.
</p>
